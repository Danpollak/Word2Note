{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Note.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danpollak/Word2Note/blob/master/DALI_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKz4WRuIZ-Qz",
        "colab_type": "text"
      },
      "source": [
        "This notebook was designed to run on local environments, and requires the DALI dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oN61HAFYlkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install dali-dataset --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "caHeyZbUiQvC",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import DALI as dali_code\n",
        "from math import log2, pow\n",
        "import pickle as pk\n",
        "import re\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XRCW4fHinGMH",
        "colab": {}
      },
      "source": [
        "dali_data_path = 'D:\\DALI\\DALI_v1.0/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7fQtM6hRo_Ld",
        "colab": {}
      },
      "source": [
        "# Load the dataset, takes time\n",
        "\n",
        "# Load all the dataset\n",
        "# dali_data = dali_code.get_the_DALI_dataset(dali_data_path, skip=[], keep=[])\n",
        "\n",
        "# load sample data\n",
        "dali_data = dali_code.get_the_DALI_dataset(dali_data_path, skip=[],keep=[])\n",
        "\n",
        "# Confirmation of data load\n",
        "# Should print ['DALI_ID' 'NAME' 'YOUTUBE' 'WORKING'] if working\n",
        "dali_info = dali_code.get_info(dali_data_path + '/info/DALI_DATA_INFO.gz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DnwRrdmEzPcu",
        "colab": {}
      },
      "source": [
        "# Auxilary functions to preprocess dataset\n",
        "A4 = 440\n",
        "C0 = A4*pow(2, -4.75)\n",
        "name = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
        "    \n",
        "def pitch(freq,isFirstNote):\n",
        "    h = round(12*log2(freq/C0))\n",
        "    octave = h // 12\n",
        "    n = h % 12\n",
        "    firstNote = '_S' if isFirstNote else ''\n",
        "    return name[n] + str(octave) + firstNote\n",
        "\n",
        "def round_time_delta(delta):\n",
        "  d = delta*10\n",
        "  d = round(d)\n",
        "  return d/10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UATXq4php8_6",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "### Create dataset to subwords-notes\n",
        "\n",
        "def DALI_to_subwords_notes:\n",
        "  data_song_keys = list(dali_data.keys())\n",
        "  only_char_reg = re.compile(\"[^a-zA-Z_\\']\")\n",
        "  fixed_song = 0\n",
        "  failed_song = 0\n",
        "\n",
        "  ds = []\n",
        "\n",
        "  for song in data_song_keys:\n",
        "    # get the data\n",
        "    song_info = dali_data[song].info\n",
        "    song_annotations = dali_data[song].annotations\n",
        "\n",
        "    # remove non-english songs\n",
        "    if song_info['metadata']['language'] != 'english':\n",
        "      continue\n",
        "\n",
        "    if song_annotations['type'] != 'vertical':\n",
        "      try:\n",
        "          dali_data[song].horizontal2vertical()\n",
        "      except Exception as e:\n",
        "          failed_song+=1\n",
        "      if song_annotations['type'] != 'vertical':\n",
        "          failed_song+=1\n",
        "          continue\n",
        "\n",
        "    # iterate over paragraphs\n",
        "    for paragraph in song_annotations['annot']['hierarchical']:\n",
        "      for line in paragraph['text']:\n",
        "        line_in_notes = []\n",
        "        line_in_words = ''\n",
        "        for word in line['text']:\n",
        "          for note in word['text']:\n",
        "            if type(note) != type({}):\n",
        "              note = word\n",
        "            \n",
        "            note_text = only_char_reg.sub('',note['text'])\n",
        "            delta = round_time_delta(note['time'][1]-note['time'][0])\n",
        "            ref_note = [note_text,pitch(note['freq'][0]),delta]\n",
        "            line_in_notes.append(ref_note)\n",
        "            line_in_words = line_in_words + note_text\n",
        "          line_in_words = line_in_words + ' '\n",
        "        ds.append([line_in_notes,line_in_words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq9h9wb1Yllz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Create dataset characters-notes\n",
        "\n",
        "def DALI_to_characters_notes:\n",
        "  data_song_keys = list(dali_data.keys())\n",
        "  only_char_reg = re.compile(\"[^a-zA-Z_\\']\")\n",
        "  fixed_song = 0\n",
        "  failed_song = 0\n",
        "\n",
        "  EMPTY_SPACE_NOTE = (' ', 'BREAK','BREAK')\n",
        "\n",
        "  ds = []\n",
        "\n",
        "  for song in data_song_keys:\n",
        "    # get the data\n",
        "    song_info = dali_data[song].info\n",
        "    song_annotations = dali_data[song].annotations\n",
        "\n",
        "    # remove non-english songs\n",
        "    if song_info['metadata']['language'] != 'english':\n",
        "      continue\n",
        "\n",
        "    if song_annotations['type'] != 'vertical':\n",
        "      try:\n",
        "          dali_data[song].horizontal2vertical()\n",
        "      except Exception as e:\n",
        "          failed_song+=1\n",
        "      if song_annotations['type'] != 'vertical':\n",
        "          failed_song+=1\n",
        "          continue\n",
        "\n",
        "    # iterate over paragraphs\n",
        "    for paragraph in song_annotations['annot']['hierarchical']:\n",
        "      for line in paragraph['text']:\n",
        "        line_in_notes = []\n",
        "        line_in_words = ''\n",
        "        for word in line['text']:\n",
        "          complete_word = ''\n",
        "          for note in word['text']:\n",
        "            if type(note) != type({}):\n",
        "              note = word\n",
        "            \n",
        "            note_text = only_char_reg.sub('',note['text'])\n",
        "              \n",
        "          for note in word['text']:\n",
        "            if type(note) != type({}):\n",
        "              note = word\n",
        "            \n",
        "            note_text = only_char_reg.sub('',note['text'])\n",
        "            index = 0\n",
        "            \n",
        "            for character in note_text:\n",
        "              line_in_notes.append((character, pitch(note['freq'][0], index == 0), note_text))\n",
        "              index+=1\n",
        "              complete_word += note_text\n",
        "            line_in_words = line_in_words + note_text\n",
        "          line_in_notes.append(EMPTY_SPACE_NOTE)\n",
        "          line_in_words = line_in_words + ' '\n",
        "        ds.append([line_in_notes,line_in_words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hyyMja-_9On-",
        "colab": {}
      },
      "source": [
        "# save dataset as pickle file\n",
        "output =  'D:/DALI/output/ds_characters_withword.pickle'\n",
        "with open(output, 'wb') as pickle_file:\n",
        "    pk.dump(ds,pickle_file,protocol=pk.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vKfuEMYaz_sU",
        "colab": {}
      },
      "source": [
        "# split the dataset to train and test\n",
        "split_rate = 0.2\n",
        "split_point= round(len(ds) * split_rate)\n",
        "train = ds[split_point:]\n",
        "test = ds[:split_point]\n",
        "DALI_dataset = {'train': train, 'test': test}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZdZtwedYlmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the split dataset as pickle file\n",
        "output =  'D:/DALI/output/ds_characters_withword_split.pickle'\n",
        "with open(output, 'wb') as pickle_file:\n",
        "    pk.dump(DALI_dataset,pickle_file,protocol=pk.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}